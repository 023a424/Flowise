{
    "description": "An agent that can route a user to the billing or technical support team, or respond conversationally",
    "nodes": [
        {
            "id": "seqConditionAgent_0",
            "position": {
                "x": 690.1552722371127,
                "y": 251.91283837942228
            },
            "type": "customNode",
            "data": {
                "id": "seqConditionAgent_0",
                "label": "Condition Agent",
                "version": 1,
                "name": "seqConditionAgent",
                "type": "ConditionAgent",
                "baseClasses": ["ConditionAgent"],
                "category": "Sequential Agents",
                "description": "Uses an agent to determine which route to take next",
                "inputParams": [
                    {
                        "label": "Condition Name",
                        "name": "conditionName",
                        "type": "string",
                        "optional": true,
                        "placeholder": "If X, then Y",
                        "id": "seqConditionAgent_0-input-conditionName-string"
                    },
                    {
                        "label": "System Prompt",
                        "name": "agentPrompt",
                        "type": "string",
                        "rows": 4,
                        "default": "You are an expert customer support routing system.\nYour job is to detect whether a customer support representative is routing a user to the technical support team, or just responding conversationally.",
                        "additionalParams": true,
                        "id": "seqConditionAgent_0-input-agentPrompt-string"
                    },
                    {
                        "label": "Human Prompt",
                        "name": "humanPrompt",
                        "type": "string",
                        "description": "This prompt will be added at the end of the messages as human message",
                        "rows": 4,
                        "default": "The previous conversation is an interaction between a customer support representative and a user.\nExtract whether the representative is routing the user to the technical support team, or just responding conversationally.\n\nIf representative want to route the user to the technical support team, respond only with the word \"TECHNICAL\".\nOtherwise, respond only with the word \"CONVERSATION\".\n\nRemember, only respond with one of the above words.",
                        "additionalParams": true,
                        "id": "seqConditionAgent_0-input-humanPrompt-string"
                    },
                    {
                        "label": "Condition Function",
                        "name": "conditionFunction",
                        "type": "conditionFunction",
                        "description": "Function to evaluate the condition",
                        "hint": {
                            "label": "How to use",
                            "value": "\n1. Must return a string value at the end of function:\n    - Any string value will be considered as the connection point to next Agent. Only 1 agent can be connected at a time.\n    - If you want to end the flow, return \"End\", and conenct the \"End\" node.\n\n2. You can get output from the agent: `$flow.output` (string)\n\n3. You can get default flow config:\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get messages from the state: `$flow.state.messages`:\n    ```json\n    [\n        {\n            \"content\": \"Hello! How can I assist you today?\",\n            \"name\": \"\",\n            \"additional_kwargs\": {},\n            \"response_metadata\": {},\n            \"tool_calls\": [],\n            \"invalid_tool_calls\": [],\n            \"usage_metadata\": {}\n        }\n    ]\n    ```\n\n5. You can get custom variables: `$vars.<variable-name>`\n\n"
                        },
                        "default": "const result = $flow.output;\n\n/* \n* In the Human Prompt, we ask LLM to respond either \"TECHNICAL\" or \"CONVERSATION\"\n* Here, we check if the agent's output contains lower case \"TECHNICAL\" \n*/\nif (result.toLowerCase().includes(\"technical\")) {\n    return \"Agent\";\n}\n\nreturn \"End\";\n};",
                        "codeExample": "const result = $flow.output;\n\n/* \n* In the Human Prompt, we ask LLM to respond either \"TECHNICAL\" or \"CONVERSATION\"\n* Here, we check if the agent's output contains lower case \"TECHNICAL\" \n*/\nif (result.toLowerCase().includes(\"technical\")) {\n    return \"Agent\";\n}\n\nreturn \"End\";\n};",
                        "hideCodeExecute": true,
                        "id": "seqConditionAgent_0-input-conditionFunction-conditionFunction"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Agent/Start",
                        "name": "agentOrStart",
                        "type": "Agent | START",
                        "list": true,
                        "id": "seqConditionAgent_0-input-agentOrStart-Agent | START"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Overwrite model to be used for this agent",
                        "id": "seqConditionAgent_0-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "conditionName": "Routing",
                    "agentOrStart": ["{{seqAgent_0.data.instance}}"],
                    "model": "",
                    "agentPrompt": "You are an expert customer support routing system.\nYour job is to detect whether a customer support representative is routing a user to the billing or technical support team, or just responding conversationally.",
                    "humanPrompt": "The previous conversation is an interaction between a customer support representative and a user.\nExtract whether the representative is routing the user to the technical support team, or just responding conversationally.\n\nIf representative want to route the user to the billing team, respond only with the word \"BILLING\".\n\nIf representative want to route the user to the technical support team, respond only with the word \"TECHNICAL\".\n\nOtherwise, respond only with the word \"CONVERSATION\".\n\nRemember, only respond with one of the above words.",
                    "conditionFunction": "const result = $flow.output;\n\n/* \n* In the Human Prompt, we ask LLM to respond either \"BILLING\" or \"TECHNICAL\" or \"CONVERSATION\"\n*/\nif (result.toLowerCase().includes(\"technical\")) {\n    return \"Technical\";\n} else if (result.toLowerCase().includes(\"billing\")) {\n    return \"Billing\";\n}\nreturn \"End\";"
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "options": [
                            {
                                "id": "seqConditionAgent_0-output-billing-Agent",
                                "name": "billing",
                                "label": "Billing",
                                "type": "Agent",
                                "isAnchor": true
                            },
                            {
                                "id": "seqConditionAgent_0-output-end-END",
                                "name": "end",
                                "label": "End",
                                "type": "END",
                                "isAnchor": true
                            },
                            {
                                "id": "seqConditionAgent_0-output-technical-Agent",
                                "name": "technical",
                                "label": "Technical",
                                "type": "Agent",
                                "isAnchor": true
                            }
                        ]
                    }
                ],
                "outputs": {
                    "output": "agent"
                },
                "selected": false
            },
            "width": 300,
            "height": 627,
            "positionAbsolute": {
                "x": 690.1552722371127,
                "y": 251.91283837942228
            },
            "selected": false,
            "dragging": false
        },
        {
            "id": "seqAgent_0",
            "position": {
                "x": 318.92046927920023,
                "y": 172.70944939307438
            },
            "type": "customNode",
            "data": {
                "id": "seqAgent_0",
                "label": "Agent",
                "version": 1,
                "name": "seqAgent",
                "type": "Agent",
                "baseClasses": ["Agent"],
                "category": "Sequential Agents",
                "inputParams": [
                    {
                        "label": "Agent Name",
                        "name": "agentName",
                        "type": "string",
                        "placeholder": "Agent",
                        "id": "seqAgent_0-input-agentName-string"
                    },
                    {
                        "label": "System Prompt",
                        "name": "agentPrompt",
                        "type": "string",
                        "rows": 4,
                        "default": "You are a research assistant who can search for up-to-date info using search engine.",
                        "id": "seqAgent_0-input-agentPrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "seqAgent_0-input-promptValues-json"
                    },
                    {
                        "label": "Update State",
                        "name": "updateStateMemory",
                        "type": "datagrid",
                        "hint": {
                            "label": "How to use",
                            "value": "\n1. Fill in the key and value pair to be updated. Key must exists in the State schema\n\n2. Agent's output is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"output\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\",\n            }\n        ],\n    }\n    ```\n\n3. You can get default flow config:\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                        },
                        "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                        "datagrid": [
                            {
                                "field": "key",
                                "headerName": "Key",
                                "editable": true
                            },
                            {
                                "field": "value",
                                "headerName": "Value",
                                "editable": true,
                                "flex": 1
                            }
                        ],
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqAgent_0-input-updateStateMemory-datagrid"
                    },
                    {
                        "label": "Update State (Code)",
                        "name": "updateStateMemoryCode",
                        "type": "code",
                        "hint": {
                            "label": "How to use",
                            "value": "\n1. Must return an object. Object must contains at least one key that matches State's schema\n\n2. Agent's output is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"output\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\",\n            }\n        ],\n    }\n    ```\n\n3. You can get default flow config:\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                        },
                        "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. This will be used when both \"Update State\" and \"Update State (Code)\" are provided. Must return an object representing the state",
                        "hideCodeExecute": true,
                        "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.output] //update state by returning an object with the same schema\n};",
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqAgent_0-input-updateStateMemoryCode-code"
                    },
                    {
                        "label": "Max Iterations",
                        "name": "maxIterations",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqAgent_0-input-maxIterations-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "optional": true,
                        "id": "seqAgent_0-input-tools-Tool"
                    },
                    {
                        "label": "Agent/Start",
                        "name": "agentOrStart",
                        "type": "Agent | START",
                        "list": true,
                        "id": "seqAgent_0-input-agentOrStart-Agent | START"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Overwrite model to be used for this agent",
                        "id": "seqAgent_0-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "agentName": "Frontline",
                    "agentPrompt": "You are frontline support staff for Flowise, a company that sells computers.\n\nBe concise in your responses.\n\nYou can chat with customers and help them with basic questions, but if the customer is having a billing or technical problem, do not try to answer the question directly or gather information.\n\nInstead, immediately transfer them to the billing or technical team by asking the user to hold for a moment.\n\nOtherwise, just respond conversationally.",
                    "tools": "",
                    "agentOrStart": ["{{seqStart_0.data.instance}}"],
                    "model": "",
                    "promptValues": "",
                    "updateStateMemory": "",
                    "updateStateMemoryCode": "",
                    "maxIterations": ""
                },
                "outputAnchors": [
                    {
                        "id": "seqAgent_0-output-seqAgent-Agent",
                        "name": "seqAgent",
                        "label": "Agent",
                        "description": "",
                        "type": "Agent"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 762,
            "selected": false,
            "positionAbsolute": {
                "x": 318.92046927920023,
                "y": 172.70944939307438
            },
            "dragging": false
        },
        {
            "id": "seqStart_0",
            "position": {
                "x": -23.52565531799918,
                "y": 347.24650644584057
            },
            "type": "customNode",
            "data": {
                "id": "seqStart_0",
                "label": "Start",
                "version": 1,
                "name": "seqStart",
                "type": "START",
                "baseClasses": ["START"],
                "category": "Sequential Agents",
                "description": "Starting point of the conversation",
                "inputParams": [],
                "inputAnchors": [
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "description": "Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat",
                        "id": "seqStart_0-input-model-BaseChatModel"
                    },
                    {
                        "label": "Agent Memory",
                        "name": "agentMemory",
                        "type": "BaseCheckpointSaver",
                        "description": "Save the state of the agent",
                        "optional": true,
                        "id": "seqStart_0-input-agentMemory-BaseCheckpointSaver"
                    },
                    {
                        "label": "State",
                        "name": "state",
                        "type": "State",
                        "description": "State is an object that is updated by nodes in the graph, passing from one node to another. Agent Memory must be connected when using State. By default, state contains \"messages\" that got updated with each message sent and received.",
                        "optional": true,
                        "id": "seqStart_0-input-state-State"
                    },
                    {
                        "label": "Input Moderation",
                        "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
                        "name": "inputModeration",
                        "type": "Moderation",
                        "optional": true,
                        "list": true,
                        "id": "seqStart_0-input-inputModeration-Moderation"
                    }
                ],
                "inputs": {
                    "model": "{{chatOpenAI_0.data.instance}}",
                    "agentMemory": "{{agentMemory_0.data.instance}}",
                    "state": "",
                    "inputModeration": ""
                },
                "outputAnchors": [
                    {
                        "id": "seqStart_0-output-seqStart-START",
                        "name": "seqStart",
                        "label": "START",
                        "description": "Starting point of the conversation",
                        "type": "START"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 382,
            "selected": false,
            "positionAbsolute": {
                "x": -23.52565531799918,
                "y": 347.24650644584057
            },
            "dragging": false
        },
        {
            "id": "seqEnd_0",
            "position": {
                "x": 1084.7297516265621,
                "y": 575.9315206975033
            },
            "type": "customNode",
            "data": {
                "id": "seqEnd_0",
                "label": "End",
                "version": 1,
                "name": "seqEnd",
                "type": "END",
                "baseClasses": ["END"],
                "category": "Sequential Agents",
                "description": "End conversation",
                "inputParams": [],
                "inputAnchors": [
                    {
                        "label": "Agent/End",
                        "name": "agentOrEnd",
                        "type": "Agent | END",
                        "id": "seqEnd_0-input-agentOrEnd-Agent | END"
                    }
                ],
                "inputs": {
                    "agentOrEnd": "{{seqConditionAgent_0.data.instance}}"
                },
                "outputAnchors": [],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 143,
            "selected": false,
            "positionAbsolute": {
                "x": 1084.7297516265621,
                "y": 575.9315206975033
            },
            "dragging": false
        },
        {
            "id": "seqAgent_1",
            "position": {
                "x": 1093.8743955644593,
                "y": -227.86488392974707
            },
            "type": "customNode",
            "data": {
                "id": "seqAgent_1",
                "label": "Agent",
                "version": 1,
                "name": "seqAgent",
                "type": "Agent",
                "baseClasses": ["Agent"],
                "category": "Sequential Agents",
                "inputParams": [
                    {
                        "label": "Agent Name",
                        "name": "agentName",
                        "type": "string",
                        "placeholder": "Agent",
                        "id": "seqAgent_1-input-agentName-string"
                    },
                    {
                        "label": "System Prompt",
                        "name": "agentPrompt",
                        "type": "string",
                        "rows": 4,
                        "default": "You are a research assistant who can search for up-to-date info using search engine.",
                        "id": "seqAgent_1-input-agentPrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "seqAgent_1-input-promptValues-json"
                    },
                    {
                        "label": "Update State",
                        "name": "updateStateMemory",
                        "type": "datagrid",
                        "hint": {
                            "label": "How to use",
                            "value": "\n1. Fill in the key and value pair to be updated. Key must exists in the State schema\n\n2. Agent's output is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"output\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\",\n            }\n        ],\n    }\n    ```\n\n3. You can get default flow config:\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                        },
                        "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                        "datagrid": [
                            {
                                "field": "key",
                                "headerName": "Key",
                                "editable": true
                            },
                            {
                                "field": "value",
                                "headerName": "Value",
                                "editable": true,
                                "flex": 1
                            }
                        ],
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqAgent_1-input-updateStateMemory-datagrid"
                    },
                    {
                        "label": "Update State (Code)",
                        "name": "updateStateMemoryCode",
                        "type": "code",
                        "hint": {
                            "label": "How to use",
                            "value": "\n1. Must return an object. Object must contains at least one key that matches State's schema\n\n2. Agent's output is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"output\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\",\n            }\n        ],\n    }\n    ```\n\n3. You can get default flow config:\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                        },
                        "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. This will be used when both \"Update State\" and \"Update State (Code)\" are provided. Must return an object representing the state",
                        "hideCodeExecute": true,
                        "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.output] //update state by returning an object with the same schema\n};",
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqAgent_1-input-updateStateMemoryCode-code"
                    },
                    {
                        "label": "Max Iterations",
                        "name": "maxIterations",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqAgent_1-input-maxIterations-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "optional": true,
                        "id": "seqAgent_1-input-tools-Tool"
                    },
                    {
                        "label": "Agent/Start",
                        "name": "agentOrStart",
                        "type": "Agent | START",
                        "list": true,
                        "id": "seqAgent_1-input-agentOrStart-Agent | START"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Overwrite model to be used for this agent",
                        "id": "seqAgent_1-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "agentName": "Billing Team",
                    "agentPrompt": "You are an expert billing support specialist for Flowise, a company that sells computers.\nHelp the user to the best of your ability, but be concise in your responses.\nYou have the ability to authorize refunds, which you can do collecting the required information.",
                    "tools": ["{{customTool_0.data.instance}}"],
                    "agentOrStart": ["{{seqConditionAgent_0.data.instance}}"],
                    "model": "",
                    "promptValues": "",
                    "updateStateMemory": "",
                    "updateStateMemoryCode": "",
                    "maxIterations": ""
                },
                "outputAnchors": [
                    {
                        "id": "seqAgent_1-output-seqAgent-Agent",
                        "name": "seqAgent",
                        "label": "Agent",
                        "description": "",
                        "type": "Agent"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 762,
            "selected": false,
            "positionAbsolute": {
                "x": 1093.8743955644593,
                "y": -227.86488392974707
            },
            "dragging": false
        },
        {
            "id": "seqAgent_2",
            "position": {
                "x": 1087.9698099719544,
                "y": 753.2275693140612
            },
            "type": "customNode",
            "data": {
                "id": "seqAgent_2",
                "label": "Agent",
                "version": 1,
                "name": "seqAgent",
                "type": "Agent",
                "baseClasses": ["Agent"],
                "category": "Sequential Agents",
                "inputParams": [
                    {
                        "label": "Agent Name",
                        "name": "agentName",
                        "type": "string",
                        "placeholder": "Agent",
                        "id": "seqAgent_2-input-agentName-string"
                    },
                    {
                        "label": "System Prompt",
                        "name": "agentPrompt",
                        "type": "string",
                        "rows": 4,
                        "default": "You are a research assistant who can search for up-to-date info using search engine.",
                        "id": "seqAgent_2-input-agentPrompt-string"
                    },
                    {
                        "label": "Format Prompt Values",
                        "name": "promptValues",
                        "description": "Assign values to the prompt variables. You can also use $flow.state.<variable-name> to get the state value",
                        "type": "json",
                        "optional": true,
                        "acceptVariable": true,
                        "list": true,
                        "id": "seqAgent_2-input-promptValues-json"
                    },
                    {
                        "label": "Update State",
                        "name": "updateStateMemory",
                        "type": "datagrid",
                        "hint": {
                            "label": "How to use",
                            "value": "\n1. Fill in the key and value pair to be updated. Key must exists in the State schema\n\n2. Agent's output is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"output\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\",\n            }\n        ],\n    }\n    ```\n\n3. You can get default flow config:\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                        },
                        "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values",
                        "datagrid": [
                            {
                                "field": "key",
                                "headerName": "Key",
                                "editable": true
                            },
                            {
                                "field": "value",
                                "headerName": "Value",
                                "editable": true,
                                "flex": 1
                            }
                        ],
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqAgent_2-input-updateStateMemory-datagrid"
                    },
                    {
                        "label": "Update State (Code)",
                        "name": "updateStateMemoryCode",
                        "type": "code",
                        "hint": {
                            "label": "How to use",
                            "value": "\n1. Must return an object. Object must contains at least one key that matches State's schema\n\n2. Agent's output is available as `$flow.output` with the following structure:\n    ```json\n    {\n        \"output\": \"Hello! How can I assist you today?\",\n        \"usedTools\": [\n            {\n                \"tool\": \"tool-name\",\n                \"toolInput\": \"{foo: var}\",\n                \"toolOutput\": \"This is the tool's output\"\n            }\n        ],\n        \"sourceDocuments\": [\n            {\n                \"pageContent\": \"This is the page content\",\n                \"metadata\": \"{foo: var}\",\n            }\n        ],\n    }\n    ```\n\n3. You can get default flow config:\n    - `$flow.sessionId`\n    - `$flow.chatId`\n    - `$flow.chatflowId`\n    - `$flow.input`\n    - `$flow.state`\n\n4. You can get custom variables: `$vars.<variable-name>`\n\n"
                        },
                        "description": "This is only applicable when you have a custom State at the START node. After agent execution, you might want to update the State values. This will be used when both \"Update State\" and \"Update State (Code)\" are provided. Must return an object representing the state",
                        "hideCodeExecute": true,
                        "codeExample": "const result = $flow.output;\n\n/* Suppose we have a custom State schema like this:\n* {\n    aggregate: {\n        value: (x, y) => x.concat(y),\n        default: () => []\n    }\n  }\n*/\n\nreturn {\n  aggregate: [result.output] //update state by returning an object with the same schema\n};",
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqAgent_2-input-updateStateMemoryCode-code"
                    },
                    {
                        "label": "Max Iterations",
                        "name": "maxIterations",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "seqAgent_2-input-maxIterations-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Tools",
                        "name": "tools",
                        "type": "Tool",
                        "list": true,
                        "optional": true,
                        "id": "seqAgent_2-input-tools-Tool"
                    },
                    {
                        "label": "Agent/Start",
                        "name": "agentOrStart",
                        "type": "Agent | START",
                        "list": true,
                        "id": "seqAgent_2-input-agentOrStart-Agent | START"
                    },
                    {
                        "label": "Chat Model",
                        "name": "model",
                        "type": "BaseChatModel",
                        "optional": true,
                        "description": "Overwrite model to be used for this agent",
                        "id": "seqAgent_2-input-model-BaseChatModel"
                    }
                ],
                "inputs": {
                    "agentName": "Technical Team",
                    "agentPrompt": "You are an expert at diagnosing technical computer issues. You work for a company called Flowise that sells computers.\n\nUse the \"search_manual\" tool to look for relavant information to answer user question to the best of your ability, be concise in your responses.",
                    "tools": ["{{retrieverTool_0.data.instance}}"],
                    "agentOrStart": ["{{seqConditionAgent_0.data.instance}}"],
                    "model": "",
                    "promptValues": "",
                    "updateStateMemory": "",
                    "updateStateMemoryCode": "",
                    "maxIterations": ""
                },
                "outputAnchors": [
                    {
                        "id": "seqAgent_2-output-seqAgent-Agent",
                        "name": "seqAgent",
                        "label": "Agent",
                        "description": "",
                        "type": "Agent"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 762,
            "selected": false,
            "positionAbsolute": {
                "x": 1087.9698099719544,
                "y": 753.2275693140612
            },
            "dragging": false
        },
        {
            "id": "chatOpenAI_0",
            "position": {
                "x": -387.91146991062465,
                "y": 273.2444623004418
            },
            "type": "customNode",
            "data": {
                "id": "chatOpenAI_0",
                "label": "ChatOpenAI",
                "version": 6,
                "name": "chatOpenAI",
                "type": "ChatOpenAI",
                "baseClasses": ["ChatOpenAI", "BaseChatModel", "BaseLanguageModel", "Runnable"],
                "category": "Chat Models",
                "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "chatOpenAI_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "gpt-3.5-turbo",
                        "id": "chatOpenAI_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Temperature",
                        "name": "temperature",
                        "type": "number",
                        "step": 0.1,
                        "default": 0.9,
                        "optional": true,
                        "id": "chatOpenAI_0-input-temperature-number"
                    },
                    {
                        "label": "Max Tokens",
                        "name": "maxTokens",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-maxTokens-number"
                    },
                    {
                        "label": "Top Probability",
                        "name": "topP",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-topP-number"
                    },
                    {
                        "label": "Frequency Penalty",
                        "name": "frequencyPenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-frequencyPenalty-number"
                    },
                    {
                        "label": "Presence Penalty",
                        "name": "presencePenalty",
                        "type": "number",
                        "step": 0.1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-presencePenalty-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "step": 1,
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-basepath-string"
                    },
                    {
                        "label": "BaseOptions",
                        "name": "baseOptions",
                        "type": "json",
                        "optional": true,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-baseOptions-json"
                    },
                    {
                        "label": "Allow Image Uploads",
                        "name": "allowImageUploads",
                        "type": "boolean",
                        "description": "Automatically uses gpt-4-vision-preview when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
                        "default": false,
                        "optional": true,
                        "id": "chatOpenAI_0-input-allowImageUploads-boolean"
                    },
                    {
                        "label": "Image Resolution",
                        "description": "This parameter controls the resolution in which the model views the image.",
                        "name": "imageResolution",
                        "type": "options",
                        "options": [
                            {
                                "label": "Low",
                                "name": "low"
                            },
                            {
                                "label": "High",
                                "name": "high"
                            },
                            {
                                "label": "Auto",
                                "name": "auto"
                            }
                        ],
                        "default": "low",
                        "optional": false,
                        "additionalParams": true,
                        "id": "chatOpenAI_0-input-imageResolution-options"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Cache",
                        "name": "cache",
                        "type": "BaseCache",
                        "optional": true,
                        "id": "chatOpenAI_0-input-cache-BaseCache"
                    }
                ],
                "inputs": {
                    "cache": "",
                    "modelName": "gpt-3.5-turbo",
                    "temperature": 0.9,
                    "maxTokens": "",
                    "topP": "",
                    "frequencyPenalty": "",
                    "presencePenalty": "",
                    "timeout": "",
                    "basepath": "",
                    "baseOptions": "",
                    "allowImageUploads": "",
                    "imageResolution": "low"
                },
                "outputAnchors": [
                    {
                        "id": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
                        "name": "chatOpenAI",
                        "label": "ChatOpenAI",
                        "description": "Wrapper around OpenAI large language models that use the Chat endpoint",
                        "type": "ChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 669,
            "selected": false,
            "positionAbsolute": {
                "x": -387.91146991062465,
                "y": 273.2444623004418
            },
            "dragging": false
        },
        {
            "id": "agentMemory_0",
            "position": {
                "x": -752.9217137598457,
                "y": 422.26240589026145
            },
            "type": "customNode",
            "data": {
                "id": "agentMemory_0",
                "label": "Agent Memory",
                "version": 1,
                "name": "agentMemory",
                "type": "AgentMemory",
                "baseClasses": ["AgentMemory", "BaseCheckpointSaver"],
                "category": "Memory",
                "description": "Memory for agentflow to remember the state of the conversation",
                "inputParams": [
                    {
                        "label": "Database",
                        "name": "databaseType",
                        "type": "options",
                        "options": [
                            {
                                "label": "SQLite",
                                "name": "sqlite"
                            }
                        ],
                        "default": "sqlite",
                        "id": "agentMemory_0-input-databaseType-options"
                    },
                    {
                        "label": "Database File Path",
                        "name": "databaseFilePath",
                        "type": "string",
                        "placeholder": "C:\\Users\\User\\.flowise\\database.sqlite",
                        "description": "If SQLite is selected, provide the path to the SQLite database file. Leave empty to use default application database",
                        "additionalParams": true,
                        "optional": true,
                        "id": "agentMemory_0-input-databaseFilePath-string"
                    },
                    {
                        "label": "Additional Connection Configuration",
                        "name": "additionalConfig",
                        "type": "json",
                        "additionalParams": true,
                        "optional": true,
                        "id": "agentMemory_0-input-additionalConfig-json"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "databaseType": "sqlite",
                    "databaseFilePath": "",
                    "additionalConfig": ""
                },
                "outputAnchors": [
                    {
                        "id": "agentMemory_0-output-agentMemory-AgentMemory|BaseCheckpointSaver",
                        "name": "agentMemory",
                        "label": "AgentMemory",
                        "description": "Memory for agentflow to remember the state of the conversation",
                        "type": "AgentMemory | BaseCheckpointSaver"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 327,
            "selected": false,
            "positionAbsolute": {
                "x": -752.9217137598457,
                "y": 422.26240589026145
            },
            "dragging": false
        },
        {
            "id": "customTool_0",
            "position": {
                "x": 689.3939044772261,
                "y": -244.1705219014559
            },
            "type": "customNode",
            "data": {
                "id": "customTool_0",
                "label": "Custom Tool",
                "version": 1,
                "name": "customTool",
                "type": "CustomTool",
                "baseClasses": ["CustomTool", "Tool", "StructuredTool", "Runnable"],
                "category": "Tools",
                "description": "Use custom tool you've created in Flowise within chatflow",
                "inputParams": [
                    {
                        "label": "Select Tool",
                        "name": "selectedTool",
                        "type": "asyncOptions",
                        "loadMethod": "listTools",
                        "id": "customTool_0-input-selectedTool-asyncOptions"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "selectedTool": ""
                },
                "outputAnchors": [
                    {
                        "id": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
                        "name": "customTool",
                        "label": "CustomTool",
                        "description": "Use custom tool you've created in Flowise within chatflow",
                        "type": "CustomTool | Tool | StructuredTool | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 285,
            "selected": false,
            "positionAbsolute": {
                "x": 689.3939044772261,
                "y": -244.1705219014559
            },
            "dragging": false
        },
        {
            "id": "retrieverTool_0",
            "position": {
                "x": 715.9482578461602,
                "y": 981.8138888826531
            },
            "type": "customNode",
            "data": {
                "id": "retrieverTool_0",
                "label": "Retriever Tool",
                "version": 2,
                "name": "retrieverTool",
                "type": "RetrieverTool",
                "baseClasses": ["RetrieverTool", "DynamicTool", "Tool", "StructuredTool", "Runnable"],
                "category": "Tools",
                "description": "Use a retriever as allowed tool for agent",
                "inputParams": [
                    {
                        "label": "Retriever Name",
                        "name": "name",
                        "type": "string",
                        "placeholder": "search_state_of_union",
                        "id": "retrieverTool_0-input-name-string"
                    },
                    {
                        "label": "Retriever Description",
                        "name": "description",
                        "type": "string",
                        "description": "When should agent uses to retrieve documents",
                        "rows": 3,
                        "placeholder": "Searches and returns documents regarding the state-of-the-union.",
                        "id": "retrieverTool_0-input-description-string"
                    },
                    {
                        "label": "Return Source Documents",
                        "name": "returnSourceDocuments",
                        "type": "boolean",
                        "optional": true,
                        "id": "retrieverTool_0-input-returnSourceDocuments-boolean"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Retriever",
                        "name": "retriever",
                        "type": "BaseRetriever",
                        "id": "retrieverTool_0-input-retriever-BaseRetriever"
                    }
                ],
                "inputs": {
                    "name": "search_manual",
                    "description": "Use this tool when you need to search for any technical information",
                    "retriever": "{{faiss_0.data.instance}}",
                    "returnSourceDocuments": ""
                },
                "outputAnchors": [
                    {
                        "id": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
                        "name": "retrieverTool",
                        "label": "RetrieverTool",
                        "description": "Use a retriever as allowed tool for agent",
                        "type": "RetrieverTool | DynamicTool | Tool | StructuredTool | Runnable"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 602,
            "selected": false,
            "positionAbsolute": {
                "x": 715.9482578461602,
                "y": 981.8138888826531
            },
            "dragging": false
        },
        {
            "id": "faiss_0",
            "position": {
                "x": 307.35383655592824,
                "y": 1047.798081140703
            },
            "type": "customNode",
            "data": {
                "id": "faiss_0",
                "label": "Faiss",
                "version": 1,
                "name": "faiss",
                "type": "Faiss",
                "baseClasses": ["Faiss", "VectorStoreRetriever", "BaseRetriever"],
                "category": "Vector Stores",
                "description": "Upsert embedded data and perform similarity search upon query using Faiss library from Meta",
                "inputParams": [
                    {
                        "label": "Base Path to load",
                        "name": "basePath",
                        "description": "Path to load faiss.index file",
                        "placeholder": "C:\\Users\\User\\Desktop",
                        "type": "string",
                        "id": "faiss_0-input-basePath-string"
                    },
                    {
                        "label": "Top K",
                        "name": "topK",
                        "description": "Number of top results to fetch. Default to 4",
                        "placeholder": "4",
                        "type": "number",
                        "additionalParams": true,
                        "optional": true,
                        "id": "faiss_0-input-topK-number"
                    }
                ],
                "inputAnchors": [
                    {
                        "label": "Document",
                        "name": "document",
                        "type": "Document",
                        "list": true,
                        "optional": true,
                        "id": "faiss_0-input-document-Document"
                    },
                    {
                        "label": "Embeddings",
                        "name": "embeddings",
                        "type": "Embeddings",
                        "id": "faiss_0-input-embeddings-Embeddings"
                    }
                ],
                "inputs": {
                    "document": "",
                    "embeddings": "{{openAIEmbeddings_0.data.instance}}",
                    "basePath": "",
                    "topK": ""
                },
                "outputAnchors": [
                    {
                        "name": "output",
                        "label": "Output",
                        "type": "options",
                        "description": "",
                        "options": [
                            {
                                "id": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
                                "name": "retriever",
                                "label": "Faiss Retriever",
                                "description": "",
                                "type": "Faiss | VectorStoreRetriever | BaseRetriever"
                            },
                            {
                                "id": "faiss_0-output-vectorStore-Faiss|SaveableVectorStore|VectorStore",
                                "name": "vectorStore",
                                "label": "Faiss Vector Store",
                                "description": "",
                                "type": "Faiss | SaveableVectorStore | VectorStore"
                            }
                        ],
                        "default": "retriever"
                    }
                ],
                "outputs": {
                    "output": "retriever"
                },
                "selected": false
            },
            "width": 300,
            "height": 458,
            "selected": false,
            "positionAbsolute": {
                "x": 307.35383655592824,
                "y": 1047.798081140703
            },
            "dragging": false
        },
        {
            "id": "openAIEmbeddings_0",
            "position": {
                "x": -60.634927960119256,
                "y": 1096.0172985600473
            },
            "type": "customNode",
            "data": {
                "id": "openAIEmbeddings_0",
                "label": "OpenAI Embeddings",
                "version": 4,
                "name": "openAIEmbeddings",
                "type": "OpenAIEmbeddings",
                "baseClasses": ["OpenAIEmbeddings", "Embeddings"],
                "category": "Embeddings",
                "description": "OpenAI API to generate embeddings for a given text",
                "inputParams": [
                    {
                        "label": "Connect Credential",
                        "name": "credential",
                        "type": "credential",
                        "credentialNames": ["openAIApi"],
                        "id": "openAIEmbeddings_0-input-credential-credential"
                    },
                    {
                        "label": "Model Name",
                        "name": "modelName",
                        "type": "asyncOptions",
                        "loadMethod": "listModels",
                        "default": "text-embedding-ada-002",
                        "id": "openAIEmbeddings_0-input-modelName-asyncOptions"
                    },
                    {
                        "label": "Strip New Lines",
                        "name": "stripNewLines",
                        "type": "boolean",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-stripNewLines-boolean"
                    },
                    {
                        "label": "Batch Size",
                        "name": "batchSize",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-batchSize-number"
                    },
                    {
                        "label": "Timeout",
                        "name": "timeout",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-timeout-number"
                    },
                    {
                        "label": "BasePath",
                        "name": "basepath",
                        "type": "string",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-basepath-string"
                    },
                    {
                        "label": "Dimensions",
                        "name": "dimensions",
                        "type": "number",
                        "optional": true,
                        "additionalParams": true,
                        "id": "openAIEmbeddings_0-input-dimensions-number"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "modelName": "text-embedding-ada-002",
                    "stripNewLines": "",
                    "batchSize": "",
                    "timeout": "",
                    "basepath": "",
                    "dimensions": ""
                },
                "outputAnchors": [
                    {
                        "id": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
                        "name": "openAIEmbeddings",
                        "label": "OpenAIEmbeddings",
                        "description": "OpenAI API to generate embeddings for a given text",
                        "type": "OpenAIEmbeddings | Embeddings"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 423,
            "selected": false,
            "positionAbsolute": {
                "x": -60.634927960119256,
                "y": 1096.0172985600473
            },
            "dragging": false
        },
        {
            "id": "seqEnd_1",
            "position": {
                "x": 1456.0084637571194,
                "y": 392.5571443002932
            },
            "type": "customNode",
            "data": {
                "id": "seqEnd_1",
                "label": "End",
                "version": 1,
                "name": "seqEnd",
                "type": "END",
                "baseClasses": ["END"],
                "category": "Sequential Agents",
                "description": "End conversation",
                "inputParams": [],
                "inputAnchors": [
                    {
                        "label": "Agent/End",
                        "name": "agentOrEnd",
                        "type": "Agent | END",
                        "id": "seqEnd_1-input-agentOrEnd-Agent | END"
                    }
                ],
                "inputs": {
                    "agentOrEnd": "{{seqAgent_1.data.instance}}"
                },
                "outputAnchors": [],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 143,
            "selected": false,
            "positionAbsolute": {
                "x": 1456.0084637571194,
                "y": 392.5571443002932
            },
            "dragging": false
        },
        {
            "id": "seqEnd_2",
            "position": {
                "x": 1434.0264650599252,
                "y": 1368.5571344360717
            },
            "type": "customNode",
            "data": {
                "id": "seqEnd_2",
                "label": "End",
                "version": 1,
                "name": "seqEnd",
                "type": "END",
                "baseClasses": ["END"],
                "category": "Sequential Agents",
                "description": "End conversation",
                "inputParams": [],
                "inputAnchors": [
                    {
                        "label": "Agent/End",
                        "name": "agentOrEnd",
                        "type": "Agent | END",
                        "id": "seqEnd_2-input-agentOrEnd-Agent | END"
                    }
                ],
                "inputs": {
                    "agentOrEnd": "{{seqAgent_2.data.instance}}"
                },
                "outputAnchors": [],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 143,
            "selected": false,
            "positionAbsolute": {
                "x": 1434.0264650599252,
                "y": 1368.5571344360717
            },
            "dragging": false
        },
        {
            "id": "stickyNote_0",
            "position": {
                "x": 689.1218507649642,
                "y": 76.38785353349391
            },
            "type": "stickyNote",
            "data": {
                "id": "stickyNote_0",
                "label": "Sticky Note",
                "version": 1,
                "name": "stickyNote",
                "type": "StickyNote",
                "baseClasses": ["StickyNote"],
                "category": "Utilities",
                "description": "Add a sticky note",
                "inputParams": [
                    {
                        "label": "",
                        "name": "note",
                        "type": "string",
                        "rows": 1,
                        "placeholder": "Type something here",
                        "optional": true,
                        "id": "stickyNote_0-input-note-string"
                    }
                ],
                "inputAnchors": [],
                "inputs": {
                    "note": "Here, we use an agent to determine the intent of previous conversations.\n\nWhether to route user to:\n- Billing\n- Technical\n- End the conversation"
                },
                "outputAnchors": [
                    {
                        "id": "stickyNote_0-output-stickyNote-StickyNote",
                        "name": "stickyNote",
                        "label": "StickyNote",
                        "description": "Add a sticky note",
                        "type": "StickyNote"
                    }
                ],
                "outputs": {},
                "selected": false
            },
            "width": 300,
            "height": 163,
            "selected": false,
            "positionAbsolute": {
                "x": 689.1218507649642,
                "y": 76.38785353349391
            },
            "dragging": false
        }
    ],
    "edges": [
        {
            "source": "chatOpenAI_0",
            "sourceHandle": "chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable",
            "target": "seqStart_0",
            "targetHandle": "seqStart_0-input-model-BaseChatModel",
            "type": "buttonedge",
            "id": "chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-seqStart_0-seqStart_0-input-model-BaseChatModel"
        },
        {
            "source": "agentMemory_0",
            "sourceHandle": "agentMemory_0-output-agentMemory-AgentMemory|BaseCheckpointSaver",
            "target": "seqStart_0",
            "targetHandle": "seqStart_0-input-agentMemory-BaseCheckpointSaver",
            "type": "buttonedge",
            "id": "agentMemory_0-agentMemory_0-output-agentMemory-AgentMemory|BaseCheckpointSaver-seqStart_0-seqStart_0-input-agentMemory-BaseCheckpointSaver"
        },
        {
            "source": "seqStart_0",
            "sourceHandle": "seqStart_0-output-seqStart-START",
            "target": "seqAgent_0",
            "targetHandle": "seqAgent_0-input-agentOrStart-Agent | START",
            "type": "buttonedge",
            "id": "seqStart_0-seqStart_0-output-seqStart-START-seqAgent_0-seqAgent_0-input-agentOrStart-Agent | START"
        },
        {
            "source": "seqAgent_0",
            "sourceHandle": "seqAgent_0-output-seqAgent-Agent",
            "target": "seqConditionAgent_0",
            "targetHandle": "seqConditionAgent_0-input-agentOrStart-Agent | START",
            "type": "buttonedge",
            "id": "seqAgent_0-seqAgent_0-output-seqAgent-Agent-seqConditionAgent_0-seqConditionAgent_0-input-agentOrStart-Agent | START"
        },
        {
            "source": "customTool_0",
            "sourceHandle": "customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable",
            "target": "seqAgent_1",
            "targetHandle": "seqAgent_1-input-tools-Tool",
            "type": "buttonedge",
            "id": "customTool_0-customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable-seqAgent_1-seqAgent_1-input-tools-Tool"
        },
        {
            "source": "seqConditionAgent_0",
            "sourceHandle": "seqConditionAgent_0-output-billing-Agent",
            "target": "seqAgent_1",
            "targetHandle": "seqAgent_1-input-agentOrStart-Agent | START",
            "type": "buttonedge",
            "id": "seqConditionAgent_0-seqConditionAgent_0-output-billing-Agent-seqAgent_1-seqAgent_1-input-agentOrStart-Agent | START"
        },
        {
            "source": "retrieverTool_0",
            "sourceHandle": "retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable",
            "target": "seqAgent_2",
            "targetHandle": "seqAgent_2-input-tools-Tool",
            "type": "buttonedge",
            "id": "retrieverTool_0-retrieverTool_0-output-retrieverTool-RetrieverTool|DynamicTool|Tool|StructuredTool|Runnable-seqAgent_2-seqAgent_2-input-tools-Tool"
        },
        {
            "source": "openAIEmbeddings_0",
            "sourceHandle": "openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings",
            "target": "faiss_0",
            "targetHandle": "faiss_0-input-embeddings-Embeddings",
            "type": "buttonedge",
            "id": "openAIEmbeddings_0-openAIEmbeddings_0-output-openAIEmbeddings-OpenAIEmbeddings|Embeddings-faiss_0-faiss_0-input-embeddings-Embeddings"
        },
        {
            "source": "faiss_0",
            "sourceHandle": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
            "target": "retrieverTool_0",
            "targetHandle": "retrieverTool_0-input-retriever-BaseRetriever",
            "type": "buttonedge",
            "id": "faiss_0-faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever-retrieverTool_0-retrieverTool_0-input-retriever-BaseRetriever"
        },
        {
            "source": "seqConditionAgent_0",
            "sourceHandle": "seqConditionAgent_0-output-technical-Agent",
            "target": "seqAgent_2",
            "targetHandle": "seqAgent_2-input-agentOrStart-Agent | START",
            "type": "buttonedge",
            "id": "seqConditionAgent_0-seqConditionAgent_0-output-technical-Agent-seqAgent_2-seqAgent_2-input-agentOrStart-Agent | START"
        },
        {
            "source": "seqConditionAgent_0",
            "sourceHandle": "seqConditionAgent_0-output-end-END",
            "target": "seqEnd_0",
            "targetHandle": "seqEnd_0-input-agentOrEnd-Agent | END",
            "type": "buttonedge",
            "id": "seqConditionAgent_0-seqConditionAgent_0-output-end-END-seqEnd_0-seqEnd_0-input-agentOrEnd-Agent | END"
        },
        {
            "source": "seqAgent_1",
            "sourceHandle": "seqAgent_1-output-seqAgent-Agent",
            "target": "seqEnd_1",
            "targetHandle": "seqEnd_1-input-agentOrEnd-Agent | END",
            "type": "buttonedge",
            "id": "seqAgent_1-seqAgent_1-output-seqAgent-Agent-seqEnd_1-seqEnd_1-input-agentOrEnd-Agent | END"
        },
        {
            "source": "seqAgent_2",
            "sourceHandle": "seqAgent_2-output-seqAgent-Agent",
            "target": "seqEnd_2",
            "targetHandle": "seqEnd_2-input-agentOrEnd-Agent | END",
            "type": "buttonedge",
            "id": "seqAgent_2-seqAgent_2-output-seqAgent-Agent-seqEnd_2-seqEnd_2-input-agentOrEnd-Agent | END"
        }
    ]
}
